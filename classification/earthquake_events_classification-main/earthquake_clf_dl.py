# -*- coding: utf-8 -*-
"""earthq_clf2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15KkS1KUywone6iNCYUlHZJT_0e0f7L4O

My accounts;
- Github -> https://github.com/john-fante
- Kaggle -> https://www.kaggle.com/banddaniel


Goal -> Mojor Event/Non-Major Event Classification (Time Series Classification)

A major event as any reading of over 5 on the Richter scale.

Data source -> https://www.timeseriesclassification.com/description.php?Dataset=Earthquakes
"""

!pip install imblearn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from scipy.io.arff import loadarff
from sklearn.utils import class_weight
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, ReLU, Conv1D, GlobalAveragePooling1D, Dense, BatchNormalization, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping

from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

# reading .arff file and converting dataframe
def arff_to_pd(path):
  data = loadarff(path)
  raw_data, meta_data = data

  cols = []
  for col_name in meta_data:
    cols.append(col_name)

  data2d = np.zeros([ raw_data.shape[0], len(cols) ])

  for row_number in range(raw_data.shape[0]):
    for col_number in range(len(cols)):
      data2d[row_number][col_number] = raw_data[row_number][col_number]

  df = pd.DataFrame(data2d, columns = cols)

  return df

train_data = arff_to_pd('/content/drive/MyDrive/Colab Notebooks/datasets/Earthquakes/Earthquakes_TRAIN.arff')
test_data = arff_to_pd('/content/drive/MyDrive/Colab Notebooks/datasets/Earthquakes/Earthquakes_TEST.arff')

X = train_data.iloc[:,0:-1]
y = train_data['target']

X.head()

# The number of classes before undersampling

y.value_counts()

# After undersampling

y.value_counts()
rum = RandomUnderSampler()

X_n, y_n = rum.fit_resample(X,y)
print(y_n.value_counts())

X_n = np.array(X_n).reshape(X_n.shape[0], X_n.shape[1], 1)
y_n = np.array(y_n).reshape(-1,1)

# Reading test set

X_test = test_data.iloc[:,0:-1]
y_test = test_data['target']

X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)

inp = Input(X_n.shape[1:])

L = Conv1D(8, 3, padding ='same',  activation ="relu")(inp)
L = BatchNormalization()(L)
L = Dropout(0.1)(L)

L = Conv1D(32, 3, padding ='same',  activation ="relu")(L)
L = BatchNormalization()(L)
L = Dropout(0.1)(L)



L = GlobalAveragePooling1D()(L)


out = Dense(2, activation ="softmax")(L)

model = Model(inputs = inp, outputs = out)
model.compile(optimizer = "adam" , loss = "sparse_categorical_crossentropy", metrics =["sparse_categorical_accuracy"] )

model.summary()

my_callbacks = [ EarlyStopping(patience =  30, monitor = "val_loss" ),
                 ReduceLROnPlateau(monitor = "val_loss", patience= 10, min_lr = 0.000001, factor = 0.5  ) ]


hist = model.fit(X_n, y_n , epochs = 100, batch_size= 2 ,validation_split=0.15,
                 callbacks = my_callbacks, verbose =1 )

pred = model.predict(X_test)

train_ev =  model.evaluate(X_n, y_n)
test_ev =  model.evaluate(X_test, y_test)


print('train acc: {0:.3f}'.format(train_ev[1]))
print('test acc: {0:.3f}'.format(test_ev[1]))

pred_ =[]

for i in range(len(pred)):
  pred_.append(np.argmax(pred[i]))

roc_auc = roc_auc_score(pred_, y_test)
print('ROC AUC Score: {0:.3f}'.format(roc_auc))


# Creatin classification report
report = classification_report(y_test, pred_)
print(report)

"""It is an overt fact that the precision of class 1 (major event) is very low. This classification performance not good."""

# Creating confusion matrix

cf = confusion_matrix(y_test, pred_)
sns.heatmap(cf, annot =True)